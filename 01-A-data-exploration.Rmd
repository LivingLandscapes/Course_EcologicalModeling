---
layout: topic
title: "Data exploration"
output: html_document
---

**Assigned Reading:**

> Zuur, A. F., E. N. Ieno, and C. S. Elphick. 2010. A protocol for data exploration to avoid common statistical problems. *Methods in Ecology and Evolution* **1**: 3-14.  [DOI: 10.1111/j.2041-210X.2009.00001.x](https://dx.doi.org/10.1111/j.2041-210X.2009.00001.x)


```{r include = FALSE}
# This code block sets up the r session when the page is rendered to html
# include = FALSE means that it will not be included in the html document

# Write every code block to the html document 
knitr::opts_chunk$set(echo = TRUE)

# Write the results of every code block to the html document 
knitr::opts_chunk$set(eval = TRUE)

# Define the directory where images generated by knit will be saved
knitr::opts_chunk$set(fig.path = "images/03-A/")

# Set the web address where R will look for files from this repository
# Do not change this address
# repo_url <- "https://raw.githubusercontent.com/fukamilab/BIO202/master/"
repo_url <- "https://raw.githubusercontent.com/LivingLandscapes/Course_EcologicalModeling/master/"
```

### Key Points

#### Data exploration

1. Outliers Y & X
+ Outliers in response variable vs in covariates - to be dealt with differently
+ Transformation less desirable for response variable than in covariates?

2. Homogeneity Y

3. Normality Y
+ Example of importance of biological intuition and graphical investigation
    + Fig 5b - transformation to get normality not desirable

4. Zero troble Y
+ Zero-inflated GLM
+ Double zeros, or joint absences - what do they mean? e.g., spatial clumping
+ Multivariate analysis that ignores double zeros

5. Collinearity X
+ VIF of 10, 3, or 2 - reason for these values?
+ VIFs, or common sense or biological knowledge
+ Also... pairwise comparisons?

6. Relationships Y & X
+ Multi-panel scatter plots for checking for outliers

7. Interactions
+ Are data balanced? Use coplot (Fig 11).

8. Independence Y
+ Mixed effects, etc. to deal with non-independence
+ ACF or variograms for checking for temporal and spatial non-independence
+ We will cover this more in our Autocorrelation Topic.

Not all steps always needed

#### Common themes

+ Biological intuition = key to make decisions about stats
+ Hypothesis testing vs hypothesis generation
    + One solution - two data sets - one to create hypotheses and one to test them
    + But only practical for large data sets
+ Emphasis on graphical tools


### Analysis Example

The code below is built on data from Roberts et al. (2022) in *Ecological Solutions and Evidence*.

```{r, include=FALSE, eval = TRUE}

# List of packages necessary to run this script:
require(librarian)
shelf(tidyverse, data.table, cowplot, gridExtra, grid, here, sp, rgdal,
      raster, rgeos, mapproj, maptools, vroom, vegan, mgcv, MuMIn, gratia)

# Path to Caleb's data
dat_grass <- 
  read.csv("https://raw.githubusercontent.com/LivingLandscapes/LargeScaleFireRestoresGrasslandBirdRichness/LargeScaleFireRestoresGrasslandBirdRichness/LargeScaleFireRestoresGrasslandBirdRichness_RProj/LoessCanyons_BBS_Data/LoessCanyonsBBS_DataRaw.csv")

```

#### Checking for outliers

Zuur et al. recommends plotting your data using boxplots and dotcharts to detect outliers. Violin plots are also great options. Before removing suspected outliers, make sure they are actually outliers!

**Boxplot**

```{r, eval = TRUE, include = TRUE}

ggplot(data = dat_grass,
       mapping = aes(y = Rich_Grass)) + 
  geom_boxplot() +
  ylab("Grassland Bird Richness")

```

**Violin plots**

Violin plots show more data distribution details, but they can be messy. These are conditional (by year) and display the 10th, 50th (i.e., median), and 90th quantiles as horizontal lines.

```{r, eval = TRUE, include = TRUE}

ggplot(data = dat_grass,
       mapping = aes(x = as.factor(Year), y = Rich_Grass, group = Year)) + 
  geom_violin(draw_quantiles = c(0.1, 0.5, 0.9)) +
  ylab("Grassland Bird Richness") + 
  xlab("Year")

```

**Dotchart for multiple variables**

I personally don't use these as much, but they can be useful.

```{r, eval = TRUE, include = TRUE}

dat_grass %>% 
  arrange(Rich_Grass) %>%
  mutate(rowID = 1:n()) %>%
  ggplot() + 
    facet_wrap(~ Year) + 
    geom_point(mapping = aes(x = Rich_Grass, y = rowID, group = Year)) + 
    xlab("Grassland Bird Richness")

```



#### What's your data's distribution?

Some statistical tests assume normal distributions, making it important to check the shape of your data. Does this histogram of grassland bird richness appear to have a "normal" distribution (i.e., Gaussian distribution)? Why or why not?

We will learn about probability distributions in our Probability Distributions Topic.

```{r, eval = TRUE, include = TRUE}

ggplot() +
    geom_histogram(data = dat_grass,
                   mapping = aes(x = Rich_Grass),
                   binwidth = 1) + 
  ylab("Frequency") +
  xlab("Grassland Bird Richness")

```

#### Collinearity? 

It's absolutely important to check for pairwise correlations, which we can do with the "pairs()" function as below. However, this should be taken with a grain of salt too. See this quote from the R Documentation for the "performance::check_collinearity()" function:

"*Multicollinearity should not be confused with a raw strong correlation between predictors... Remember: "Pairwise correlations are not the problem. It is the conditional associations - not correlations - that matter." (McElreath 2020, p. 169)*"

We will talk about Zuur's preference of "variance inflation factors" to check for collinearity in the Linear models review Topic.

```{r, eval = TRUE, include = TRUE}

cor(dat_grass[ , c("Year", "Burned", "mean", "stdDev", "TSF")])

```


#### Is there actually a relationship between X and Y?!

For this, we want to plot the response/dependent variable (grassland bird richness) against potential predictor/independent variables. Here, I use quick-and-dirty generalized additive models per ggplot2::geom_smooth and then combine the plots with cowplot::plot_grid

```{r, eval = TRUE, include = TRUE}

# Making individual plots
rich_treeMean <- 
  dat_grass %>%
  ggplot(aes(x = mean, y = Rich_Grass)) + 
  geom_point() + 
  geom_smooth(method = "gam", formula = y ~ s(x)) + # a simple generalized additive model!
  ylab("Grassland Bird Richness") + 
  xlab("Mean % Tree Cover") + 
  theme_classic() # FYI: there are lots of fun pre-made themes in ggplot2
rich_TSF <- 
  dat_grass %>%
  ggplot(aes(x = TSF, y = Rich_Grass)) + 
  geom_point() + 
  geom_smooth(method = "gam", formula = y ~ s(x)) +
  ylab("Grassland Bird Richness") + 
  xlab("Years-since-fire") + 
  theme_bw() # Another theme

# Combine plots
cowplot::plot_grid(rich_treeMean, rich_TSF, ncol = 2)

```

#### Should we consider interactions between predictor variables?

```{r, eval = TRUE, include = TRUE}

pairs(dat_grass[ , c("Year", "Burned", "mean", "stdDev", "TSF")],
      lower.panel = NULL)

```

<!-- *** -->


<!-- ### Discussion Questions -->

<!-- **Q1:** When should you let go of an outlier? -->

<!-- **Q2:** How can you check for independence using multivariate data?  -->

<!-- > "Hence, it is important to check whether there is dependence in the raw data before doing the analysis, and also the residuals afterwards. These checks can be made by plotting the response variable vs. time or spatial coordinates." -->


<!-- **Q3:** _To transform or not to transform? That is the question._ -->

<!-- > "There are three main reasons for a transformation: **to reduce the effect of outliers** (especially in covariates), **to stabilize the variance** and **to linearize relationships**. However, using more advanced techniques like GLS and GAMs, heterogenity and nonlinearity problems can be solved, making transformation less important." -->


<!-- **Q4:** What are some data exploration techniques you have used? -->


<!-- *** -->

<!-- ### After-class follow-up -->

<!-- + beeswarm functions recommended by Anna to look at data distribution: -->

<!-- [ggbeeswarm](https://cran.r-project.org/web/packages/ggbeeswarm/index.html) -->

<!-- [ggbeeswarm vignette](https://cran.r-project.org/web/packages/ggbeeswarm/vignettes/usageExamples.pdf) -->

<!-- [beeswarm](http://www.cbs.dtu.dk/~eklund/beeswarm/) -->

<!-- + O'Hara and Kotze 2010 Do not log-transform count data: -->

<!-- [Publication](http://onlinelibrary.wiley.com/doi/10.1111/j.2041-210X.2010.00021.x/abstract) -->

<!-- [Blog post](https://www.r-bloggers.com/do-not-log-transform-count-data-bitches/) -->


<!-- + Paper Tad mentioned that uses "principal coordinate analysis of a truncated distance matrix" (PCNM) to incorporate spaptial trends in multivariate data: -->

<!-- [Toju et al. 2017](http://web.stanford.edu/~fukamit/toju-et-al-2017-accepted.pdf) -->

<!-- Also, from Sandra: the PCNM (truncated distance matrix) method is discussed starting on page 244 of this book: https://link.springer.com/content/pdf/10.1007%2F978-1-4419-7976-6.pdf -->
