---
layout: topic
title: "Hierarchical Generalized Additive Models"
output: html_document
---

**Assigned Reading:**

- Pedersen, E. J., Miller, D. L., Simpson, G. L., & Ross, N. (2019). Hierarchical generalized additive models in ecology: an introduction with mgcv. PeerJ, 7, e6876.
- Lawton, D., Scarth, P., Deveson, E., Piou, C., Spessa, A., Waters, C., & Cease, A. J. (2022). Seeing the locust in the swarm: accounting for spatiotemporal hierarchy improves ecological models of insect populations. Ecography, 2022(2).

```{r include = FALSE}

# This code block sets up the r session when the page is rendered to html
# include = FALSE means that it will not be included in the html document

# Write every code block to the html document 
knitr::opts_chunk$set(echo = TRUE)

# Write the results of every code block to the html document 
knitr::opts_chunk$set(eval = TRUE)

# Set the web address where R will look for files from this repository
# Do not change this address
repo_url <- "https://raw.githubusercontent.com/LivingLandscapes/Course_EcologicalModeling/master/"

# Suppress warnings and messages
knitr::opts_chunk$set(warning = FALSE, message = FALSE) 

```

## Overview

To learn about hierarchical generalized additive models (HGAMs), we are going to use weather station data from grassland ecoregions in the Great Plains, USA. We will be asking if two factors that affect fire intensity, *minimum relative humidity* and *maximum wind speed*, are changing between 2010 and 2019. 

<p>
![Photo credit: Christine Chitwood](https://github.com/LivingLandscapes/Course_EcologicalModeling/raw/master/images/RS.jpg){width=300px}
<p>

A brief description of the data:

- Year = years from 2010 - 2019
- Month = numeric code for months May - Sept
- Day = Julian day of year
- Veg_Type = rangeland ecoregion
- Lat = latitude
- Long = longitude
- Station_ID = weather station unique identifier code
- RH_per_min = minimum percent relative humidity between 0600 - 1800 per day
- Wind_mph_max = maximum wind speed (mph) between 0600 - 1800 per day

```{r, include = TRUE, eval = TRUE, message = FALSE}

# List of packages necessary to run this script:
require(librarian, quietly = TRUE)
shelf(tidyverse, 
      mgcv, # For checking model convergence
      MuMIn, # for model selection
      gratia, # for ggplot functionality with mgcv
      # DHARMa, # for model diagnostics
      vroom, # for loading data FAST
      lib = tempdir(),
      quiet = TRUE)

# Set the web address where R will look for files from this repository
# Do not change this address
repo_url <- "https://raw.githubusercontent.com/LivingLandscapes/Course_EcologicalModeling/master/"

# Load data
weather <- 
  vroom(paste0(repo_url, "/data/FireWeather.csv"))

```

### Data Exploration

**On your own, familiarize yourself with the data.** Below, you can see that we're deadling with >100k rows and *many* potential grouping variables.

```{r, eval = TRUE, message = FALSE, include = TRUE}

# Number of columns and rows?
dim(weather) # >100k rows!

# How many unique values in each column?
weather %>%
  summarize(across(everything(), ~ length(unique(.x))))

# Some preparations for mgcv
weather <- 
  weather %>%
  mutate(across(c(Veg_Type, Station_ID), 
                as.factor)) %>% # mgcv wants factors for random effect 
  mutate(RH_per_min = RH_per_min + 0.001,
         Wind_mph_max = Wind_mph_max + 0.001) %>% # for log link
  mutate(across(c(Year, Day, Lat, Long),
                ~ (.x - mean(.x)) / sd(.x),
                .names = "{.col}_scaled")) # scale covariates

```

### "Random Intercept": Model G

Let's first try the simplest HGAM: estimate a single global function for our covariate of interest (Year) plus a individual-level random effect intercept for ecoregion. **On your own, investigate each model diagnostic call (commented out in the chunk below) and interpret.** Look at the R help for more information, and ask Caleb if you have more questions.

```{r eval = TRUE, message = FALSE, include = TRUE}

# Create model G using bam()
rh_modG <- 
  bam(RH_per_min ~ s(Year) + 
        s(Day, bs = "cc") + # Note cubic regression spline
        te(Long, Lat) + # tensor smooth lets latitude/longitude 'interact'
        s(Veg_Type, bs = "re"), # Random effect for ecoregion
      family = gaussian("log"), # Why this link?!
      data = weather,
      method = "fREML") # need to use fREML for fast fitting.

# # Some basic model diagnostics
# summary(rh_modG)
# gam.check(rh_modG)
# gratia::appraise(rh_modG)

```

Okay, so the model isn't the greatest for a few reasons (can you list some?). However, it's also not a complete disaster. So for fun--and so we can see how "random intercepts" work with HGAMs--let's plot some predictions.

```{r eval = TRUE, message = FALSE, include = TRUE}

# setup prediction data. This is a little tricky because for ggplot, we only
# want one latitude/longitude for each ecoregion AND we want to make sure the
# correct latitude/longitudes get paired with their respective ecoregions. Doing
# this with a left_join()
rh_modG_pred <-
  with(weather,
       left_join(
         expand.grid(
           Year = 2010:2019,
           Day = median(Day), # Only using the middle day here!
           Veg_Type = unique(Veg_Type)
         ),
         data.frame( # Getting only the mean lat/long by ecoregion
           Lat = summarize(weather %>%
                             group_by(Veg_Type),
                           Lat = mean(Lat))$Lat,
           Long = summarize(weather %>%
                              group_by(Veg_Type),
                            Long = mean(Long))$Long,
           Veg_Type = sort(unique(Veg_Type)) # Make sure ecoregions are in correct order!
         )
       ))

# make the prediction, add this and a column of standard errors to the prediction
# data.frame. Predictions are on the log scale.
rh_modG_pred <- cbind(rh_modG_pred,
                       predict(rh_modG, 
                               rh_modG_pred, 
                               se.fit = TRUE, 
                               type = "response"))

# make the plot.
ggplot(data = rh_modG_pred) +
  facet_wrap(~ Veg_Type) +
  geom_ribbon(aes(ymin = fit - 1.96 * se.fit, 
                  ymax = fit + 1.96 * se.fit, 
                  x = Year, 
                  group = Veg_Type),
              fill = "grey80") +
  geom_line(aes(x = Year, 
                y = fit, 
                group = Veg_Type),
            color = "darkred") +
  scale_x_continuous(breaks = c(2010, 2013, 2016, 2019)) + 
  labs(x = "Year",
       y = "Minimum Relative Humidity (%)")

```

**On your own, interpret these prediction plots.** Remember the values we fed the predict() function when you're interpreting. For instance, what does it mean that we only used the median Julian day in these predictions?

### "Random Slope": Model GS
