---
layout: topic
title: "Hierarchical Generalized Additive Models"
output: html_document
---

**Assigned Reading:**

- Pedersen, E. J., Miller, D. L., Simpson, G. L., & Ross, N. (2019). Hierarchical generalized additive models in ecology: an introduction with mgcv. PeerJ, 7, e6876.
- Lawton, D., Scarth, P., Deveson, E., Piou, C., Spessa, A., Waters, C., & Cease, A. J. (2022). Seeing the locust in the swarm: accounting for spatiotemporal hierarchy improves ecological models of insect populations. Ecography, 2022(2).

```{r include = FALSE}

# This code block sets up the r session when the page is rendered to html
# include = FALSE means that it will not be included in the html document

# Write every code block to the html document 
knitr::opts_chunk$set(echo = TRUE)

# Write the results of every code block to the html document 
knitr::opts_chunk$set(eval = TRUE)

# Set the web address where R will look for files from this repository
# Do not change this address
repo_url <- "https://raw.githubusercontent.com/LivingLandscapes/Course_EcologicalModeling/master/"

# Suppress warnings and messages
knitr::opts_chunk$set(warning = FALSE, message = FALSE) 

```

## Overview

To learn about hierarchical generalized additive models (HGAMs), we are going to use weather station data from grassland ecoregions in the Great Plains, USA. We will be asking if two factors that affect fire intensity, *minimum relative humidity* and *maximum wind speed*, are changing between 2010 and 2019. 

<p>
![](https://github.com/LivingLandscapes/Course_EcologicalModeling/raw/master/images/RS.jpg){width=600px}
<p>

A brief description of the data:

- Year = years from 2010 - 2019
- Month = numeric code for months May - Sept
- Day = Julian day of year
- Veg_Type = rangeland ecoregion
- Lat = latitude
- Long = longitude
- Station_ID = weather station unique identifier code
- RH_per_min = minimum percent relative humidity between 0600 - 1800 per day
- Wind_mph_max = maximum wind speed (mph) between 0600 - 1800 per day

```{r, include = TRUE, eval = TRUE, message = FALSE}

# List of packages necessary to run this script:
require(librarian, quietly = TRUE)
shelf(tidyverse, 
      mgcv, # For checking model convergence
      MuMIn, # for model selection
      gratia, # for ggplot functionality with mgcv
      # DHARMa, # for model diagnostics
      vroom, # for loading data FAST
      lib = tempdir(),
      quiet = TRUE)

# Set the web address where R will look for files from this repository
# Do not change this address
# repo_url <- "https://raw.githubusercontent.com/LivingLandscapes/Course_EcologicalModeling/master/"
repo_url <- "C:/Users/cr065/Documents/GitHub/Course_EcologicalModeling"

# Load data
weather <- 
  vroom(paste0(repo_url, "/data/FireWeather.csv"))

```

### Data Exploration

**On your own, familiarize yourself with the data.** Below, you can see that we're deadling with >100k rows and *many* potential grouping variables.

```{r, eval = TRUE, message = FALSE, include = TRUE}

# Number of columns and rows?
dim(weather) # >100k rows!

# How many unique values in each column?
weather %>%
  summarize(across(everything(), ~ length(unique(.x))))

# Some preparations for mgcv
weather <- 
  weather %>%
  mutate(across(c(Veg_Type, Station_ID), 
                as.factor)) %>% # mgcv wants factors for random effect 
  mutate(RH_per_min = RH_per_min + 0.001,
         Wind_mph_max = Wind_mph_max + 0.001) %>% # for log link
  mutate(across(c(Year, Day, Lat, Long),
                ~ (.x - mean(.x)) / sd(.x),
                .names = "{.col}_scaled")) # scale covariates

```

### Simplest HGAM: Model G

```{r eval = TRUE, message = FALSE, include = TRUE}



# 
rh_modG <- 
  bam(RH_per_min ~ s(Year) + 
        s(Day, bs = "cc") + te(Long, Lat) + 
        s(Veg_Type, bs = "re"),
      family = gaussian("log"),
      data = weather,
      method = "fREML")

```

...

```{r eval = TRUE, message = FALSE, include = TRUE}

# setup prediction data. This is a little tricky because for ggplot, we only want one latitude/longitude for each ecoregion AND we want to make sure the correct latitude/longitudes get paired with their respective ecoregions. Doing this with a left_join()
rh_modG_pred <- 
  with(
    weather,
    left_join(expand.grid(
      Year = 2010:2019,
      Day = median(Day), # Only using the middle day here!
      Veg_Type = sort(unique(Veg_Type))
    ),
    data.frame(Lat = summarize(weather %>%
                      group_by(Veg_Type),
                    Lat = mean(Lat))$Lat,
    Long = summarize(weather %>%
                       group_by(Veg_Type),
                     Long = mean(Long))$Long,
    Veg_Type = sort(unique(Veg_Type)))
  ))

# make the prediction, add this and a column of standard errors to the prediction
# data.frame. Predictions are on the log scale.
rh_modG_pred <- cbind(rh_modG_pred,
                       predict(rh_modG, 
                               rh_modG_pred, 
                               se.fit = TRUE, 
                               type = "response"))

# make the plot.
ggplot(data = rh_modG_pred) +
  facet_wrap(~ Veg_Type) +
  geom_ribbon(aes(ymin = fit - 1.96 * se.fit, 
                  ymax = fit + 1.96 * se.fit, 
                  x = Year, 
                  group = Veg_Type),
              fill = "grey80") +
  geom_line(aes(x = Year, 
                y = fit, 
                group = Veg_Type),
            color = "darkred") +
  labs(x = "Year",
       y = "Minimum Relative Humidity (%)")

```



### 
